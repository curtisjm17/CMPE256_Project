{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from itertools import combinations\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Signature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file containing Signature Matrix\n",
    "fr = open('../data/signature_matrix_10_hashes.csv', 'r')\n",
    "reader = csv.reader(fr)\n",
    "\n",
    "# Initial signature matrix array\n",
    "sig_mat = np.empty([10, 2262292], dtype=int)\n",
    "\n",
    "# Loop through each row of signature matrix file\n",
    "t0 = time.time()\n",
    "count = 0\n",
    "for row in reader:\n",
    "    \n",
    "    # Convert string of signature row to integers\n",
    "    row_2_int = []\n",
    "    for ele in row:\n",
    "        row_2_int.append(int(ele))\n",
    "    sig_mat[count] = row_2_int\n",
    "    \n",
    "    # Display status\n",
    "    count = count + 1\n",
    "    if count%100 == 0:\n",
    "        print('Row', count, '-', time.time()-t0, 'sec')\n",
    "        \n",
    "# Close file\n",
    "fr.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The signature matrix is loaded here instead of calculated in place due to memory constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Signature Matrix to LSH Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track 0 - 0.0010559558868408203 sec\n",
      "Track 1000000 - 14.83893370628357 sec\n",
      "Track 2000000 - 29.999577045440674 sec\n"
     ]
    }
   ],
   "source": [
    "# Transpose signature matrix for easier processing\n",
    "sig_mat = sig_mat.T\n",
    "\n",
    "# Open file to write LSH values\n",
    "fw = open('../data/LSH_matrix_1rows_10bands.csv', 'w', newline='')\n",
    "writer = csv.writer(fw, delimiter=',')\n",
    "\n",
    "# Set number of rows and bands\n",
    "bands = 10\n",
    "num_rows = 1\n",
    "\n",
    "# Loop through each track in signature matrix\n",
    "t0 = time.time()\n",
    "for track in range(0, len(sig_mat)):\n",
    "    \n",
    "    # Loop through each band and hash rows in band\n",
    "    LSH_per_track = []\n",
    "    for band in range(0, bands):\n",
    "        LSH_val = ''\n",
    "        for i in range(num_rows*(band), num_rows*(band+1)):\n",
    "            LSH_val = LSH_val + str(sig_mat[track][i])\n",
    "        \n",
    "        # Append hash value to list\n",
    "        LSH_per_track.append(LSH_val)\n",
    "    \n",
    "    # Write hash values to file\n",
    "    writer.writerow(LSH_per_track)\n",
    "    \n",
    "    # Display status\n",
    "    if int(track)%1000000 == 0:\n",
    "        print('Track', track, '-', time.time()-t0, 'sec')\n",
    "        \n",
    "# Close file\n",
    "fw.close()\n",
    "\n",
    "# Clear out memory\n",
    "LSH_val = []\n",
    "LSH_per_track = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values within bands are hashed together simply being concatenating the row values together is strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Candidate Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track 100000 - 1.3220610618591309 sec\n",
      "Track 200000 - 2.5837528705596924 sec\n",
      "Track 300000 - 4.077269792556763 sec\n",
      "Track 400000 - 5.4822328090667725 sec\n",
      "Track 500000 - 6.625729560852051 sec\n",
      "Track 600000 - 8.103623151779175 sec\n",
      "Track 700000 - 9.237990140914917 sec\n",
      "Track 800000 - 10.766067028045654 sec\n",
      "Track 900000 - 11.90809941291809 sec\n",
      "Track 1000000 - 13.064009189605713 sec\n",
      "Track 1100000 - 14.15366268157959 sec\n",
      "Track 1200000 - 15.757372856140137 sec\n",
      "Track 1300000 - 16.84849500656128 sec\n",
      "Track 1400000 - 17.93740177154541 sec\n",
      "Track 1500000 - 19.00943922996521 sec\n",
      "Track 1600000 - 20.065755367279053 sec\n",
      "Track 1700000 - 21.809739351272583 sec\n",
      "Track 1800000 - 22.83500385284424 sec\n",
      "Track 1900000 - 23.876986980438232 sec\n",
      "Track 2000000 - 24.886589288711548 sec\n",
      "Track 2100000 - 25.896191596984863 sec\n",
      "Track 2200000 - 26.921202898025513 sec\n"
     ]
    }
   ],
   "source": [
    "# Open file containing LSH values\n",
    "fr = open('../data/LSH_matrix_1rows_10bands.csv', 'r')\n",
    "reader = csv.reader(fr, delimiter=',')\n",
    "bands = 10\n",
    "num_rows = 1\n",
    "\n",
    "# Initialize dictionary to store hash values and candidate pairs\n",
    "hash_value = {}\n",
    "can_pairs = {}\n",
    "for band in range(0,bands):\n",
    "    hash_value[band] = {}\n",
    "    can_pairs[band] = {}\n",
    "    \n",
    "# Initialize  counter\n",
    "count = [0]*bands\n",
    "track_num = 0\n",
    "t0 = time.time()\n",
    "\n",
    "# Loop through each track in LSH file\n",
    "for track in reader:\n",
    "    \n",
    "    # Loop through each LSH value\n",
    "    for band in range(0, len(track)):\n",
    "        \n",
    "        # Check if LSH value already exists in dictionary\n",
    "        ID = hash_value[band].get(track[band], '')\n",
    "        \n",
    "        # Add new value to dictionaries\n",
    "        if len(str(ID)) == 0:\n",
    "            hash_value[band][track[band]] = count[band]\n",
    "            can_pairs[band][count[band]] = list([track_num])\n",
    "            count[band] = count[band] + 1\n",
    "        \n",
    "        # Add value to existing dictionary entry\n",
    "        else:\n",
    "            idx = can_pairs[band].get(ID, '')\n",
    "            idx.append(track_num)\n",
    "            can_pairs[band][ID] = idx\n",
    "\n",
    "    # Display Progress\n",
    "    track_num = track_num + 1\n",
    "    if track_num%100000==0:\n",
    "        print('Track', track_num, '-', time.time()-t0, 'sec')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first identifies unique hash value for each band. Those hash values are mapped to integer values to cut down on memory to store the hash values. Tracks containing the same hash value for a band are grouped together in a dictionary with their corresponding integer hash value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band: 0 Pair: 100000 Elapsed Time: 30.43355631828308\n",
      "Band: 0 Pair: 200000 Elapsed Time: 38.3123893737793\n",
      "Band: 0 Pair: 300000 Elapsed Time: 41.36923098564148\n",
      "Band: 2 Pair: 100000 Elapsed Time: 192.26182293891907\n",
      "Band: 2 Pair: 200000 Elapsed Time: 205.5378818511963\n",
      "Band: 3 Pair: 100000 Elapsed Time: 404.07649302482605\n",
      "Band: 4 Pair: 100000 Elapsed Time: 616.5628888607025\n",
      "Band: 5 Pair: 100000 Elapsed Time: 800.0707890987396\n",
      "Band: 5 Pair: 200000 Elapsed Time: 834.2893526554108\n",
      "Band: 6 Pair: 100000 Elapsed Time: 1010.415447473526\n",
      "Band: 6 Pair: 200000 Elapsed Time: 1052.432700395584\n",
      "Band: 6 Pair: 300000 Elapsed Time: 1068.1772487163544\n",
      "Band: 7 Pair: 100000 Elapsed Time: 1290.4585177898407\n",
      "Band: 7 Pair: 200000 Elapsed Time: 1334.1056187152863\n",
      "Band: 7 Pair: 300000 Elapsed Time: 1346.0175111293793\n",
      "Band: 8 Pair: 100000 Elapsed Time: 1614.2044532299042\n",
      "Band: 8 Pair: 200000 Elapsed Time: 1660.2299053668976\n",
      "Band: 9 Pair: 100000 Elapsed Time: 2099.1339468955994\n"
     ]
    }
   ],
   "source": [
    "#Initialize dictionary to store candidate pairs\n",
    "cp_dict = dict()\n",
    "\n",
    "# Loop through each band of LSH matrix\n",
    "t0 = time.time()\n",
    "for band in range(0,bands):\n",
    "    \n",
    "    # Loop through each unique LSH value\n",
    "    count = 0\n",
    "    for key, value in can_pairs[band].items():\n",
    "        \n",
    "        # If LSH value has moe than one track, create candidate pair\n",
    "        if len(value) > 1:\n",
    "            \n",
    "            # Create combinations of track in LSH value\n",
    "            combs = list(combinations(value, 2))\n",
    "\n",
    "            # Process pair to list in a sorted order\n",
    "            for single_pair in combs:\n",
    "                single_pair = list(single_pair)\n",
    "                single_pair.sort()\n",
    "                \n",
    "                # Add candidate pair to dictionary so that duplicates are discarded\n",
    "                cp_dict[str(single_pair[0]) + ' ' + str(single_pair[1])]=1\n",
    "        \n",
    "        # Display status\n",
    "        count = count+1\n",
    "        if (count%100000 == 0) & (count > 0):\n",
    "            print('Band:', band, 'Pair:', count, 'Elapsed Time:', time.time()-t0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step goes through each hash value for each bands and produces the each combination of candidates pairs based on those binning. The combinations are then added to a dictionary to remove all duplicate candidate pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate Pair: 25000000 Elapsed Time: 113.16815376281738\n",
      "Candidate Pair: 50000000 Elapsed Time: 225.45030426979065\n",
      "Candidate Pair: 75000000 Elapsed Time: 347.2551169395447\n",
      "Candidate Pair: 100000000 Elapsed Time: 480.99227643013\n",
      "Candidate Pair: 125000000 Elapsed Time: 611.557375907898\n",
      "Candidate Pair: 150000000 Elapsed Time: 727.8755617141724\n",
      "Candidate Pair: 175000000 Elapsed Time: 852.7852604389191\n",
      "Candidate Pair: 200000000 Elapsed Time: 974.5959830284119\n",
      "Candidate Pair: 225000000 Elapsed Time: 1101.9907069206238\n",
      "Candidate Pair: 250000000 Elapsed Time: 1228.560359954834\n",
      "Candidate Pair: 275000000 Elapsed Time: 1354.701090335846\n",
      "Candidate Pair: 300000000 Elapsed Time: 1460.0194356441498\n",
      "Candidate Pair: 325000000 Elapsed Time: 1569.8908081054688\n"
     ]
    }
   ],
   "source": [
    "# Initialize numpy array to store all candidate pairs\n",
    "cand_pair_array = np.empty([len(cp_dict)*2,2], dtype=int)\n",
    "\n",
    "# Loop through each candidate pair in dictionary\n",
    "count = 0\n",
    "t0 = time.time()\n",
    "for key in cp_dict:\n",
    "    \n",
    "    # Split string into track of candidate pair\n",
    "    can_pair_values = key.split()\n",
    "    can_pair_value_0 = int(can_pair_values[0])\n",
    "    can_pair_value_1 = int(can_pair_values[1])\n",
    "    \n",
    "    # Add candidate to array\n",
    "    cand_pair_array[2*count] = [can_pair_value_0, can_pair_value_1]\n",
    "    \n",
    "    # Add candidate pair in reverse order to easier searching later\n",
    "    cand_pair_array[2*count+1] = [can_pair_value_1, can_pair_value_0]\n",
    "    \n",
    "    # Display status\n",
    "    count = count + 1\n",
    "    if (count%25000000 == 0):\n",
    "        print('Candidate Pair:', count, 'Elapsed Time:', time.time()-t0) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The candidate pair dictionary is now converted to a numpy array due to the decreased size of storage. Each candidate pair is added to the array twice: once in order 0, 1 and once in order 1, 0. Later when searching for similar songs, it will be easier being able to search just the first column of the candidate pairs array instead of both columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 32.90532469749451\n"
     ]
    }
   ],
   "source": [
    "# Write Candidate Pair array to pickle file\n",
    "t0 = time.time()\n",
    "with open('../data/candidate_pair_1rows_10bands.pickle', 'wb') as f:\n",
    "    pickle.dump(cand_pair_array, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Display Status\n",
    "print('Elapsed time:', time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
