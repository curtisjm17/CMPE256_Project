{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from itertools import combinations\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Signature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file containing Signature Matrix\n",
    "fr = open('./data/signature_matrix_10_hashes.csv', 'r')\n",
    "reader = csv.reader(fr)\n",
    "\n",
    "# Initial signature matrix array\n",
    "sig_mat = np.empty([10, 2262292], dtype=int)\n",
    "\n",
    "# Loop through each row of signature matrix file\n",
    "t0 = time.time()\n",
    "count = 0\n",
    "for row in reader:\n",
    "    \n",
    "    # Convert string of signature row to integers\n",
    "    row_2_int = []\n",
    "    for ele in row:\n",
    "        row_2_int.append(int(ele))\n",
    "    sig_mat[count] = row_2_int\n",
    "    \n",
    "    # Display status\n",
    "    count = count + 1\n",
    "    if count%100 == 0:\n",
    "        print('Row', count, '-', time.time()-t0, 'sec')\n",
    "        \n",
    "# Close file\n",
    "fr.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The signature matrix is loaded here instead of calculated in place due to memory constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Signature Matrix to LSH Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track 0 - 0.0 sec\n",
      "Track 1000000 - 16.04891014099121 sec\n",
      "Track 2000000 - 32.29577994346619 sec\n"
     ]
    }
   ],
   "source": [
    "# Transpose signature matrix for easier processing\n",
    "sig_mat = sig_mat.T\n",
    "\n",
    "# Open file to write LSH values\n",
    "fw = open('./data/LSH_matrix_1rows_10bands.csv', 'w', newline='')\n",
    "writer = csv.writer(fw, delimiter=',')\n",
    "\n",
    "# Set number of rows and bands\n",
    "bands = 10\n",
    "num_rows = 1\n",
    "\n",
    "# Loop through each track in signature matrix\n",
    "t0 = time.time()\n",
    "for track in range(0, len(sig_mat)):\n",
    "    \n",
    "    # Loop through each band and hash rows in band\n",
    "    LSH_per_track = []\n",
    "    for band in range(0, bands):\n",
    "        LSH_val = ''\n",
    "        for i in range(num_rows*(band), num_rows*(band+1)):\n",
    "            LSH_val = LSH_val + str(sig_mat[track][i])\n",
    "        \n",
    "        # Append hash value to list\n",
    "        LSH_per_track.append(LSH_val)\n",
    "    \n",
    "    # Write hash values to file\n",
    "    writer.writerow(LSH_per_track)\n",
    "    \n",
    "    # Display status\n",
    "    if int(track)%1000000 == 0:\n",
    "        print('Track', track, '-', time.time()-t0, 'sec')\n",
    "        \n",
    "# Close file\n",
    "fw.close()\n",
    "\n",
    "# Clear out memory\n",
    "LSH_val = []\n",
    "LSH_per_track = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values within bands are hashed together simply being concatenating the row values together is strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Candidate Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track 100000 - 1.4738233089447021 sec\n",
      "Track 200000 - 3.0178606510162354 sec\n",
      "Track 300000 - 4.452858209609985 sec\n",
      "Track 400000 - 5.955823659896851 sec\n",
      "Track 500000 - 7.522373676300049 sec\n",
      "Track 600000 - 8.762340307235718 sec\n",
      "Track 700000 - 10.406372547149658 sec\n",
      "Track 800000 - 11.653377532958984 sec\n",
      "Track 900000 - 12.880340337753296 sec\n",
      "Track 1000000 - 14.658340692520142 sec\n",
      "Track 1100000 - 15.866341829299927 sec\n",
      "Track 1200000 - 17.02937602996826 sec\n",
      "Track 1300000 - 18.18537425994873 sec\n",
      "Track 1400000 - 20.019372940063477 sec\n",
      "Track 1500000 - 21.14843440055847 sec\n",
      "Track 1600000 - 22.289466619491577 sec\n",
      "Track 1700000 - 23.41043519973755 sec\n",
      "Track 1800000 - 24.53381323814392 sec\n",
      "Track 1900000 - 25.659815788269043 sec\n",
      "Track 2000000 - 27.681851625442505 sec\n",
      "Track 2100000 - 28.78685235977173 sec\n",
      "Track 2200000 - 29.896848440170288 sec\n"
     ]
    }
   ],
   "source": [
    "# Open file containing LSH values\n",
    "fr = open('./data/LSH_matrix_1rows_10bands.csv', 'r')\n",
    "reader = csv.reader(fr, delimiter=',')\n",
    "bands = 10\n",
    "num_rows = 1\n",
    "\n",
    "# Initialize dictionary to store hash values and candidate pairs\n",
    "hash_value = {}\n",
    "can_pairs = {}\n",
    "for band in range(0,bands):\n",
    "    hash_value[band] = {}\n",
    "    can_pairs[band] = {}\n",
    "    \n",
    "# Initialize  counter\n",
    "count = [0]*bands\n",
    "track_num = 0\n",
    "t0 = time.time()\n",
    "\n",
    "# Loop through each track in LSH file\n",
    "for track in reader:\n",
    "    \n",
    "    # Loop through each LSH value\n",
    "    for band in range(0, len(track)):\n",
    "        \n",
    "        # Check if LSH value already exists in dictionary\n",
    "        ID = hash_value[band].get(track[band], '')\n",
    "        \n",
    "        # Add new value to dictionaries\n",
    "        if len(str(ID)) == 0:\n",
    "            hash_value[band][track[band]] = count[band]\n",
    "            can_pairs[band][count[band]] = list([track_num])\n",
    "            count[band] = count[band] + 1\n",
    "        \n",
    "        # Add value to existing dictionary entry\n",
    "        else:\n",
    "            idx = can_pairs[band].get(ID, '')\n",
    "            idx.append(track_num)\n",
    "            can_pairs[band][ID] = idx\n",
    "\n",
    "    # Display Progress\n",
    "    track_num = track_num + 1\n",
    "    if track_num%100000==0:\n",
    "        print('Track', track_num, '-', time.time()-t0, 'sec')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first identifies unique hash value for each band. Those hash values are mapped to integer values to cut down on memory to store the hash values. Tracks containing the same hash value for a band are grouped together in a dictionary with their corresponding integer hash value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band: 0 Pair: 100000 Elapsed Time: 34.4864296913147\n",
      "Band: 0 Pair: 200000 Elapsed Time: 43.24747014045715\n",
      "Band: 1 Pair: 100000 Elapsed Time: 79.73155903816223\n",
      "Band: 1 Pair: 200000 Elapsed Time: 88.69052362442017\n",
      "Band: 1 Pair: 300000 Elapsed Time: 92.0345208644867\n",
      "Band: 2 Pair: 100000 Elapsed Time: 131.98002648353577\n",
      "Band: 2 Pair: 200000 Elapsed Time: 140.1440007686615\n",
      "Band: 3 Pair: 100000 Elapsed Time: 211.63511395454407\n",
      "Band: 4 Pair: 100000 Elapsed Time: 258.0588264465332\n",
      "Band: 4 Pair: 200000 Elapsed Time: 266.9956395626068\n",
      "Band: 4 Pair: 300000 Elapsed Time: 270.5084662437439\n",
      "Band: 5 Pair: 100000 Elapsed Time: 358.981972694397\n",
      "Band: 6 Pair: 100000 Elapsed Time: 647.5936095714569\n",
      "Band: 7 Pair: 100000 Elapsed Time: 801.5435185432434\n",
      "Band: 7 Pair: 200000 Elapsed Time: 830.5925507545471\n",
      "Band: 8 Pair: 100000 Elapsed Time: 1025.246957540512\n",
      "Band: 8 Pair: 200000 Elapsed Time: 1066.0816280841827\n",
      "Band: 8 Pair: 300000 Elapsed Time: 1079.005847454071\n",
      "Band: 9 Pair: 100000 Elapsed Time: 1344.6546320915222\n"
     ]
    }
   ],
   "source": [
    "#Initialize dictionary to store candidate pairs\n",
    "cp_dict = dict()\n",
    "\n",
    "# Loop through each band of LSH matrix\n",
    "t0 = time.time()\n",
    "for band in range(0,bands):\n",
    "    \n",
    "    # Loop through each unique LSH value\n",
    "    count = 0\n",
    "    for key, value in can_pairs[band].items():\n",
    "        \n",
    "        # If LSH value has moe than one track, create candidate pair\n",
    "        if len(value) > 1:\n",
    "            \n",
    "            # Create combinations of track in LSH value\n",
    "            combs = list(combinations(value, 2))\n",
    "\n",
    "            # Process pair to list in a sorted order\n",
    "            for single_pair in combs:\n",
    "                single_pair = list(single_pair)\n",
    "                single_pair.sort()\n",
    "                \n",
    "                # Add candidate pair to dictionary so that duplicates are discarded\n",
    "                cp_dict[str(single_pair[0]) + ' ' + str(single_pair[1])]=1\n",
    "        \n",
    "        # Display status\n",
    "        count = count+1\n",
    "        if (count%100000 == 0) & (count > 0):\n",
    "            print('Band:', band, 'Pair:', count, 'Elapsed Time:', time.time()-t0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step goes through each hash value for each bands and produces the each combination of candidates pairs based on those binning. The combinations are then added to a dictionary to remove all duplicate candidate pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate Pair: 25000000 Elapsed Time: 100.5557336807251\n",
      "Candidate Pair: 50000000 Elapsed Time: 199.9537115097046\n",
      "Candidate Pair: 75000000 Elapsed Time: 302.30594992637634\n",
      "Candidate Pair: 100000000 Elapsed Time: 403.317414522171\n",
      "Candidate Pair: 125000000 Elapsed Time: 506.94103741645813\n",
      "Candidate Pair: 150000000 Elapsed Time: 611.6281332969666\n",
      "Candidate Pair: 175000000 Elapsed Time: 708.7125873565674\n",
      "Candidate Pair: 200000000 Elapsed Time: 817.2377650737762\n",
      "Candidate Pair: 225000000 Elapsed Time: 913.2822206020355\n"
     ]
    }
   ],
   "source": [
    "# Initialize numpy array to store all candidate pairs\n",
    "cand_pair_array = np.empty([len(cp_dict)*2,2], dtype=int)\n",
    "\n",
    "# Loop through each candidate pair in dictionary\n",
    "count = 0\n",
    "t0 = time.time()\n",
    "for key in cp_dict:\n",
    "    \n",
    "    # Split string into track of candidate pair\n",
    "    can_pair_values = key.split()\n",
    "    can_pair_value_0 = int(can_pair_values[0])\n",
    "    can_pair_value_1 = int(can_pair_values[1])\n",
    "    \n",
    "    # Add candidate to array\n",
    "    cand_pair_array[2*count] = [can_pair_value_0, can_pair_value_1]\n",
    "    \n",
    "    # Add candidate pair in reverse order to easier searching later\n",
    "    cand_pair_array[2*count+1] = [can_pair_value_1, can_pair_value_0]\n",
    "    \n",
    "    # Display status\n",
    "    count = count + 1\n",
    "    if (count%25000000 == 0):\n",
    "        print('Candidate Pair:', count, 'Elapsed Time:', time.time()-t0) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The candidate pair dictionary is now converted to a numpy array due to the decreased size of storage. Each candidate pair is added to the array twice: once in order 0, 1 and once in order 1, 0. Later when searching for similar songs, it will be easier being able to search just the first column of the candidate pairs array instead of both columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 25.784220695495605\n"
     ]
    }
   ],
   "source": [
    "# Write Candidate Pair array to pickle file\n",
    "t0 = time.time()\n",
    "with open('./data/candidate_pair_1rows_10bands.pickle', 'wb') as f:\n",
    "    pickle.dump(cand_pair_array, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Display Status\n",
    "print('Elapsed time:', time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
