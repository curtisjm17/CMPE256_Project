{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07688027",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pyspark not needed for this script, jsut testing\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.ml.feature import MinHashLSH\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1b2fe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01736508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7675fd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import vstack\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8253e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[4]\") \\\n",
    "    .appName(\"SparkTest\") \\\n",
    "    .getOrCreate()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b003524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list of sparse vectors?\n",
    "data = [(0, Vectors.sparse(6, [0, 1, 2], [1.0, 1.0, 1.0]),),\n",
    "        (1, Vectors.sparse(6, [2, 3, 4], [1.0, 1.0, 1.0]),),\n",
    "        (2, Vectors.sparse(6, [0, 2, 4], [1.0, 1.0, 1.0]),)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f25fd1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, SparseVector(6, {0: 1.0, 1: 1.0, 2: 1.0})), (1, SparseVector(6, {2: 1.0, 3: 1.0, 4: 1.0})), (2, SparseVector(6, {0: 1.0, 2: 1.0, 4: 1.0}))]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23be25ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data, [\"id\", \"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5d37d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[butts: bigint, features: vector]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eeeb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick up going through this example:\n",
    "#https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.feature.MinHashLSH.html#pyspark.ml.feature.MinHashLSH.numHashTables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:w_pyspark]",
   "language": "python",
   "name": "conda-env-w_pyspark-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
